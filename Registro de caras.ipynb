{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cmake\n",
      "  Downloading cmake-3.30.5-py3-none-win_amd64.whl.metadata (6.4 kB)\n",
      "Downloading cmake-3.30.5-py3-none-win_amd64.whl (35.6 MB)\n",
      "   ---------------------------------------- 0.0/35.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.8/35.6 MB 16.7 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 10.5/35.6 MB 32.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 18.6/35.6 MB 35.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 27.5/35.6 MB 37.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  35.4/35.6 MB 38.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 35.6/35.6 MB 34.3 MB/s eta 0:00:00\n",
      "Installing collected packages: cmake\n",
      "Successfully installed cmake-3.30.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlib\n",
      "  Downloading dlib-19.24.6.tar.gz (3.4 MB)\n",
      "     ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.5/3.4 MB 5.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.4/3.4 MB 15.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for dlib\n",
      "Failed to build dlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [69 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_ext\n",
      "      C:\\Users\\jm246\\AppData\\Local\\Temp\\pip-install-y7w88q3b\\dlib_c673d7f7e7d14c3dbfe045a04b5edec8\\setup.py:163: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "        if LooseVersion(cmake_version) < '3.1.0':\n",
      "      Building extension for Python 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]\n",
      "      Invoking CMake setup: 'cmake C:\\Users\\jm246\\AppData\\Local\\Temp\\pip-install-y7w88q3b\\dlib_c673d7f7e7d14c3dbfe045a04b5edec8\\tools\\python -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\\Users\\jm246\\AppData\\Local\\Temp\\pip-install-y7w88q3b\\dlib_c673d7f7e7d14c3dbfe045a04b5edec8\\build\\lib.win-amd64-cpython-311 -DPYTHON_EXECUTABLE=C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -DDLIB_USE_FFMPEG=OFF -DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\\Users\\jm246\\AppData\\Local\\Temp\\pip-install-y7w88q3b\\dlib_c673d7f7e7d14c3dbfe045a04b5edec8\\build\\lib.win-amd64-cpython-311 -A x64'\n",
      "      -- Building for: NMake Makefiles\n",
      "      CMake Error at CMakeLists.txt:5 (message):\n",
      "      \n",
      "      \n",
      "      \n",
      "        !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "      \n",
      "      \n",
      "        You must use Visual Studio to build a python extension on windows.  If you\n",
      "        are getting this error it means you have not installed Visual C++.  Note\n",
      "        that there are many flavors of Visual Studio, like Visual Studio for C#\n",
      "        development.  You need to install Visual Studio for C++.\n",
      "      \n",
      "      \n",
      "        !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "      \n",
      "      \n",
      "      \n",
      "      \n",
      "      -- Configuring incomplete, errors occurred!\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Temp\\pip-install-y7w88q3b\\dlib_c673d7f7e7d14c3dbfe045a04b5edec8\\setup.py\", line 243, in <module>\n",
      "          setup(\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\__init__.py\", line 87, in setup\n",
      "          return distutils.core.setup(**attrs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\n",
      "          return run_commands(dist)\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\n",
      "          dist.run_commands()\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 968, in run_commands\n",
      "          self.run_command(cmd)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 987, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wheel\\bdist_wheel.py\", line 325, in run\n",
      "          self.run_command(\"build\")\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 319, in run_command\n",
      "          self.distribution.run_command(command)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 987, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build.py\", line 132, in run\n",
      "          self.run_command(cmd_name)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 319, in run_command\n",
      "          self.distribution.run_command(command)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 987, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Temp\\pip-install-y7w88q3b\\dlib_c673d7f7e7d14c3dbfe045a04b5edec8\\setup.py\", line 168, in run\n",
      "          self.build_extension(ext)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Temp\\pip-install-y7w88q3b\\dlib_c673d7f7e7d14c3dbfe045a04b5edec8\\setup.py\", line 206, in build_extension\n",
      "          subprocess.check_call(cmake_setup, cwd=build_folder)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 413, in check_call\n",
      "          raise CalledProcessError(retcode, cmd)\n",
      "      subprocess.CalledProcessError: Command '['cmake', 'C:\\\\Users\\\\jm246\\\\AppData\\\\Local\\\\Temp\\\\pip-install-y7w88q3b\\\\dlib_c673d7f7e7d14c3dbfe045a04b5edec8\\\\tools\\\\python', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\\\\Users\\\\jm246\\\\AppData\\\\Local\\\\Temp\\\\pip-install-y7w88q3b\\\\dlib_c673d7f7e7d14c3dbfe045a04b5edec8\\\\build\\\\lib.win-amd64-cpython-311', '-DPYTHON_EXECUTABLE=C:\\\\Users\\\\jm246\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe', '-DDLIB_USE_FFMPEG=OFF', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\\\\Users\\\\jm246\\\\AppData\\\\Local\\\\Temp\\\\pip-install-y7w88q3b\\\\dlib_c673d7f7e7d14c3dbfe045a04b5edec8\\\\build\\\\lib.win-amd64-cpython-311', '-A', 'x64']' returned non-zero exit status 1.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for dlib\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (dlib)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition\n",
      "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
      "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
      "     ---------------------------------------- 0.0/100.1 MB ? eta -:--:--\n",
      "      -------------------------------------- 2.4/100.1 MB 19.2 MB/s eta 0:00:06\n",
      "     ---- --------------------------------- 11.0/100.1 MB 32.8 MB/s eta 0:00:03\n",
      "     ------- ------------------------------ 19.9/100.1 MB 35.9 MB/s eta 0:00:03\n",
      "     ---------- --------------------------- 28.6/100.1 MB 37.7 MB/s eta 0:00:02\n",
      "     ------------- ------------------------ 36.7/100.1 MB 38.2 MB/s eta 0:00:02\n",
      "     ----------------- -------------------- 45.4/100.1 MB 38.5 MB/s eta 0:00:02\n",
      "     -------------------- ----------------- 53.7/100.1 MB 38.4 MB/s eta 0:00:02\n",
      "     ----------------------- -------------- 62.1/100.1 MB 38.8 MB/s eta 0:00:01\n",
      "     -------------------------- ----------- 71.0/100.1 MB 39.1 MB/s eta 0:00:01\n",
      "     ------------------------------ ------- 80.0/100.1 MB 39.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ---- 88.3/100.1 MB 39.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ - 97.3/100.1 MB 39.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  100.1/100.1 MB 39.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  100.1/100.1 MB 39.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- 100.1/100.1 MB 34.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\jm246\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (8.1.3)\n",
      "Collecting dlib>=19.7 (from face_recognition)\n",
      "  Using cached dlib-19.24.6.tar.gz (3.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\jm246\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (1.23.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\jm246\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (9.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jm246\\appdata\\roaming\\python\\python311\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
      "Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Building wheels for collected packages: dlib, face-recognition-models\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for dlib\n",
      "  Building wheel for face-recognition-models (setup.py): started\n",
      "  Building wheel for face-recognition-models (setup.py): finished with status 'done'\n",
      "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566184 sha256=14bd298f01350e5115d0edc4ace530df0d703222da21e4c571fdc1a52177d8d3\n",
      "  Stored in directory: c:\\users\\jm246\\appdata\\local\\pip\\cache\\wheels\\04\\52\\ec\\9355da79c29f160b038a20c784db2803c2f9fa2c8a462c176a\n",
      "Successfully built face-recognition-models\n",
      "Failed to build dlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [69 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_ext\n",
      "      C:\\Users\\jm246\\AppData\\Local\\Temp\\pip-install-od3nllix\\dlib_e08bf586fe13407f8ba64b4ab8d25977\\setup.py:163: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "        if LooseVersion(cmake_version) < '3.1.0':\n",
      "      Building extension for Python 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]\n",
      "      Invoking CMake setup: 'cmake C:\\Users\\jm246\\AppData\\Local\\Temp\\pip-install-od3nllix\\dlib_e08bf586fe13407f8ba64b4ab8d25977\\tools\\python -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\\Users\\jm246\\AppData\\Local\\Temp\\pip-install-od3nllix\\dlib_e08bf586fe13407f8ba64b4ab8d25977\\build\\lib.win-amd64-cpython-311 -DPYTHON_EXECUTABLE=C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -DDLIB_USE_FFMPEG=OFF -DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\\Users\\jm246\\AppData\\Local\\Temp\\pip-install-od3nllix\\dlib_e08bf586fe13407f8ba64b4ab8d25977\\build\\lib.win-amd64-cpython-311 -A x64'\n",
      "      -- Building for: NMake Makefiles\n",
      "      CMake Error at CMakeLists.txt:5 (message):\n",
      "      \n",
      "      \n",
      "      \n",
      "        !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "      \n",
      "      \n",
      "        You must use Visual Studio to build a python extension on windows.  If you\n",
      "        are getting this error it means you have not installed Visual C++.  Note\n",
      "        that there are many flavors of Visual Studio, like Visual Studio for C#\n",
      "        development.  You need to install Visual Studio for C++.\n",
      "      \n",
      "      \n",
      "        !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "      \n",
      "      \n",
      "      \n",
      "      \n",
      "      -- Configuring incomplete, errors occurred!\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Temp\\pip-install-od3nllix\\dlib_e08bf586fe13407f8ba64b4ab8d25977\\setup.py\", line 243, in <module>\n",
      "          setup(\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\__init__.py\", line 87, in setup\n",
      "          return distutils.core.setup(**attrs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\n",
      "          return run_commands(dist)\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\n",
      "          dist.run_commands()\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 968, in run_commands\n",
      "          self.run_command(cmd)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 987, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wheel\\bdist_wheel.py\", line 325, in run\n",
      "          self.run_command(\"build\")\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 319, in run_command\n",
      "          self.distribution.run_command(command)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 987, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\command\\build.py\", line 132, in run\n",
      "          self.run_command(cmd_name)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 319, in run_command\n",
      "          self.distribution.run_command(command)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 987, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Temp\\pip-install-od3nllix\\dlib_e08bf586fe13407f8ba64b4ab8d25977\\setup.py\", line 168, in run\n",
      "          self.build_extension(ext)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Temp\\pip-install-od3nllix\\dlib_e08bf586fe13407f8ba64b4ab8d25977\\setup.py\", line 206, in build_extension\n",
      "          subprocess.check_call(cmake_setup, cwd=build_folder)\n",
      "        File \"C:\\Users\\jm246\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 413, in check_call\n",
      "          raise CalledProcessError(retcode, cmd)\n",
      "      subprocess.CalledProcessError: Command '['cmake', 'C:\\\\Users\\\\jm246\\\\AppData\\\\Local\\\\Temp\\\\pip-install-od3nllix\\\\dlib_e08bf586fe13407f8ba64b4ab8d25977\\\\tools\\\\python', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\\\\Users\\\\jm246\\\\AppData\\\\Local\\\\Temp\\\\pip-install-od3nllix\\\\dlib_e08bf586fe13407f8ba64b4ab8d25977\\\\build\\\\lib.win-amd64-cpython-311', '-DPYTHON_EXECUTABLE=C:\\\\Users\\\\jm246\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe', '-DDLIB_USE_FFMPEG=OFF', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\\\\Users\\\\jm246\\\\AppData\\\\Local\\\\Temp\\\\pip-install-od3nllix\\\\dlib_e08bf586fe13407f8ba64b4ab8d25977\\\\build\\\\lib.win-amd64-cpython-311', '-A', 'x64']' returned non-zero exit status 1.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for dlib\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (dlib)\n"
     ]
    }
   ],
   "source": [
    "!pip install cmake\n",
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
      "  Using cached face_recognition_models-0.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\jm246\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (8.1.3)\n",
      "Collecting dlib>=19.7 (from face_recognition)\n",
      "  Using cached dlib-19.24.6.tar.gz (3.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\jm246\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (1.23.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\jm246\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (9.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jm246\\appdata\\roaming\\python\\python311\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
      "Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): finished with status 'done'\n",
      "  Created wheel for dlib: filename=dlib-19.24.6-cp311-cp311-win_amd64.whl size=2871850 sha256=f0d671b8f011e72fd811f8d82dea19ab32d5a5fabd4e8525ab637cca31ec6109\n",
      "  Stored in directory: c:\\users\\jm246\\appdata\\local\\pip\\cache\\wheels\\fe\\c7\\1f\\c778b9f7cc6d8d0da4f6697f619f9eb5a49d54d2a2c8267f3c\n",
      "Successfully built dlib\n",
      "Installing collected packages: face-recognition-models, dlib, face_recognition\n",
      "Successfully installed dlib-19.24.6 face-recognition-models-0.3.0 face_recognition-1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
      "  Using cached face_recognition_models-0.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\jm246\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (8.1.3)\n",
      "Collecting dlib>=19.7 (from face_recognition)\n",
      "  Using cached dlib-19.24.6.tar.gz (3.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\jm246\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (1.23.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\jm246\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (9.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jm246\\appdata\\roaming\\python\\python311\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
      "Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): finished with status 'done'\n",
      "  Created wheel for dlib: filename=dlib-19.24.6-cp311-cp311-win_amd64.whl size=2871887 sha256=0497571a4d2f6220c318571b6bdf1761009af692fe7162e82c2b3873ae229170\n",
      "  Stored in directory: c:\\users\\jm246\\appdata\\local\\pip\\cache\\wheels\\fe\\c7\\1f\\c778b9f7cc6d8d0da4f6697f619f9eb5a49d54d2a2c8267f3c\n",
      "Successfully built dlib\n",
      "Installing collected packages: face-recognition-models, dlib, face_recognition\n",
      "Successfully installed dlib-19.24.6 face-recognition-models-0.3.0 face_recognition-1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install face_recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1001']\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition as fr\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Accedemos a la carpeta con las imágenes de las personas\n",
    "path = 'Personal'\n",
    "images = []\n",
    "nombres = []\n",
    "lista = os.listdir(path)\n",
    "\n",
    "# Leemos los rostros desde la base de datos\n",
    "for archivo in lista:\n",
    "    # Leemos las imágenes de los rostros\n",
    "    imgdb = cv2.imread(f'{path}/{archivo}')\n",
    "    # Almacenamos la imagen\n",
    "    images.append(imgdb)\n",
    "    # Almacenamos el nombre\n",
    "    nombres.append(os.path.splitext(archivo)[0])\n",
    "\n",
    "print(nombres)\n",
    "\n",
    "def codificar_rostros(images):\n",
    "    lista_codificaciones = []\n",
    "    # Iteramos a través de las imágenes para codificarlas\n",
    "    for img in images:\n",
    "        # Corrección de color (de BGR a RGB)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # Codificamos la imagen\n",
    "        codificacion = fr.face_encodings(img)[0]\n",
    "        # Almacenamos la codificación\n",
    "        lista_codificaciones.append(codificacion)\n",
    "    return lista_codificaciones\n",
    "\n",
    "def horario(nombre):\n",
    "    # Abrimos el archivo en modo lectura y escritura\n",
    "    if not os.path.exists('Horario.csv'):\n",
    "        with open('Horario.csv', 'w') as archivo:\n",
    "            archivo.write('Nombre, Fecha, Hora')\n",
    "    with open('Horario.csv', 'r+') as archivo:\n",
    "        # Leemos la información\n",
    "        data = archivo.readlines()\n",
    "        # Creamos una lista para los nombres existentes\n",
    "        lista_nombres = []\n",
    "        # Iteramos cada línea del archivo\n",
    "        for linea in data:\n",
    "            # Buscamos la entrada y la separamos por comas\n",
    "            entrada = linea.split(', ')\n",
    "            # Almacenamos los nombres\n",
    "            lista_nombres.append(entrada[0])\n",
    "        # Verificamos si el nombre no está ya registrado\n",
    "        if nombre not in lista_nombres:\n",
    "            # Extraemos información actual (fecha y hora)\n",
    "            info = datetime.now()\n",
    "            fecha = info.strftime('%Y-%m-%d')\n",
    "            hora = info.strftime('%H:%M:%S')\n",
    "            # Guardamos la información en el archivo\n",
    "            archivo.writelines(f'\\n{nombre}, {fecha}, {hora}')\n",
    "            print(f\"Registro guardado para {nombre} a las {hora} del {fecha}\")\n",
    "\n",
    "# Llamamos a la función para codificar los rostros de la base de datos\n",
    "rostros_codificados = codificar_rostros(images)\n",
    "\n",
    "# Accedemos a la cámara\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "frame_counter = 0\n",
    "while True:\n",
    "    # Leemos un frame de la cámara\n",
    "    ret, frame = cap.read()\n",
    "    frame_counter += 1\n",
    "    if frame_counter % 2 != 0:\n",
    "        continue\n",
    "    if not ret:\n",
    "        break\n",
    "    # Reducimos el tamaño del frame para que el procesamiento sea más rápido\n",
    "    frame_pequeño = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    frame_pequeño = cv2.cvtColor(frame_pequeño, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Encontramos todas las caras en el frame actual de la cámara\n",
    "    ubicaciones_rostros = fr.face_locations(frame_pequeño, model='hog')\n",
    "    codificaciones_rostros = fr.face_encodings(frame_pequeño, ubicaciones_rostros, num_jitters=1)\n",
    "\n",
    "    for codificacion_rostro, ubicacion_rostro in zip(codificaciones_rostros, ubicaciones_rostros):\n",
    "        # Comparamos las caras detectadas con nuestras codificaciones conocidas\n",
    "        coincidencias = fr.compare_faces(rostros_codificados, codificacion_rostro, tolerance=0.6)\n",
    "        nombre = \"Desconocido\"\n",
    "\n",
    "        # Verificamos si encontramos una coincidencia\n",
    "        if True in coincidencias:\n",
    "            indice_coincidencia = coincidencias.index(True)\n",
    "            nombre = nombres[indice_coincidencia]\n",
    "            # Registramos el horario de ingreso\n",
    "            horario(nombre)\n",
    "\n",
    "        # Escalamos de nuevo las ubicaciones de los rostros al tamaño original del frame\n",
    "        top, right, bottom, left = ubicacion_rostro\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Dibujamos un rectángulo alrededor de la cara detectada\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 3)\n",
    "        # Mostramos el nombre de la persona detectada\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "        cv2.putText(frame, nombre, (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Mostramos el frame con las detecciones\n",
    "    cv2.imshow('Reconocimiento Facial', frame)\n",
    "\n",
    "    # Salir del bucle si presionamos la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberamos la cámara y cerramos todas las ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### deteccion mas fluida "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1001']\n",
      "Registro guardado para 1001 a las 20:36:51 del 2024-11-03\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition as fr\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Accedemos a la carpeta con las imágenes de las personas\n",
    "path = 'Personal'\n",
    "images = []\n",
    "nombres = []\n",
    "lista = os.listdir(path)\n",
    "\n",
    "# Leemos los rostros desde la base de datos\n",
    "for archivo in lista:\n",
    "    # Leemos las imágenes de los rostros\n",
    "    imgdb = cv2.imread(f'{path}/{archivo}')\n",
    "    # Almacenamos la imagen\n",
    "    images.append(imgdb)\n",
    "    # Almacenamos el nombre\n",
    "    nombres.append(os.path.splitext(archivo)[0])\n",
    "\n",
    "print(nombres)\n",
    "\n",
    "def codificar_rostros(images):\n",
    "    lista_codificaciones = []\n",
    "    # Iteramos a través de las imágenes para codificarlas\n",
    "    for img in images:\n",
    "        # Corrección de color (de BGR a RGB)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # Codificamos la imagen\n",
    "        codificacion = fr.face_encodings(img)[0]\n",
    "        # Almacenamos la codificación\n",
    "        lista_codificaciones.append(codificacion)\n",
    "    return lista_codificaciones\n",
    "\n",
    "def horario(nombre):\n",
    "    # Abrimos el archivo en modo lectura y escritura\n",
    "    if not os.path.exists('Horario.csv'):\n",
    "        with open('Horario.csv', 'w') as archivo:\n",
    "            archivo.write('Nombre, Fecha, Hora')\n",
    "    with open('Horario.csv', 'r+') as archivo:\n",
    "        # Leemos la información\n",
    "        data = archivo.readlines()\n",
    "        # Creamos una lista para los nombres existentes\n",
    "        lista_nombres = []\n",
    "        # Iteramos cada línea del archivo\n",
    "        for linea in data:\n",
    "            # Buscamos la entrada y la separamos por comas\n",
    "            entrada = linea.split(', ')\n",
    "            # Almacenamos los nombres\n",
    "            lista_nombres.append(entrada[0])\n",
    "        # Verificamos si el nombre no está ya registrado\n",
    "        if nombre not in lista_nombres:\n",
    "            # Extraemos información actual (fecha y hora)\n",
    "            info = datetime.now()\n",
    "            fecha = info.strftime('%Y-%m-%d')\n",
    "            hora = info.strftime('%H:%M:%S')\n",
    "            # Guardamos la información en el archivo\n",
    "            archivo.writelines(f'\\n{nombre}, {fecha}, {hora}')\n",
    "            print(f\"Registro guardado para {nombre} a las {hora} del {fecha}\")\n",
    "\n",
    "# Llamamos a la función para codificar los rostros de la base de datos\n",
    "rostros_codificados = codificar_rostros(images)\n",
    "\n",
    "# Accedemos a la cámara\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "frame_counter = 0\n",
    "while True:\n",
    "    # Leemos un frame de la cámara\n",
    "    ret, frame = cap.read()\n",
    "    frame_counter += 1\n",
    "    if frame_counter % 2 != 0:\n",
    "        continue\n",
    "    if not ret:\n",
    "        break\n",
    "    # Reducimos el tamaño del frame para que el procesamiento sea más rápido\n",
    "    frame_pequeño = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    frame_pequeño = cv2.cvtColor(frame_pequeño, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Encontramos todas las caras en el frame actual de la cámara\n",
    "    ubicaciones_rostros = fr.face_locations(frame_pequeño, model='hog')\n",
    "    codificaciones_rostros = fr.face_encodings(frame_pequeño, ubicaciones_rostros, num_jitters=1)\n",
    "\n",
    "    for codificacion_rostro, ubicacion_rostro in zip(codificaciones_rostros, ubicaciones_rostros):\n",
    "        # Comparamos las caras detectadas con nuestras codificaciones conocidas\n",
    "        coincidencias = fr.compare_faces(rostros_codificados, codificacion_rostro, tolerance=0.6)\n",
    "        nombre = \"Desconocido\"\n",
    "\n",
    "        # Verificamos si encontramos una coincidencia\n",
    "        if True in coincidencias:\n",
    "            indice_coincidencia = coincidencias.index(True)\n",
    "            nombre = nombres[indice_coincidencia]\n",
    "            # Registramos el horario de ingreso\n",
    "            horario(nombre)\n",
    "\n",
    "        # Escalamos de nuevo las ubicaciones de los rostros al tamaño original del frame\n",
    "        top, right, bottom, left = ubicacion_rostro\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Dibujamos un rectángulo alrededor de la cara detectada\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 1)\n",
    "        # Mostramos el nombre de la persona detectada\n",
    "        cv2.putText(frame, nombre, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 1)\n",
    "\n",
    "    # Mostramos el frame con las detecciones\n",
    "    cv2.imshow('Reconocimiento Facial', frame)\n",
    "\n",
    "    # Salir del bucle si presionamos la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberamos la cámara y cerramos todas las ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm246\\AppData\\Local\\Temp\\ipykernel_8608\\525238186.py:241: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  imageF = imageF.resize((1280, 720), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "from ultralytics import YOLO  # Importa la clase YOLO correctamente\n",
    "import numpy as np\n",
    "from tkinter import Tk, Label\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import face_recognition as fr\n",
    "from datetime import datetime\n",
    "\n",
    "# Definir el modelo YOLO como global\n",
    "model = YOLO('best-3.pt')  # Asegúrate de usar la clase/método correcto para YOLO\n",
    "\n",
    "# Definir las clases de tu modelo entrenado\n",
    "classes = ['Gafas', 'Casco', 'Persona', 'Chaleco']  # Clases de tu modelo\n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))  # Colores aleatorios para cada clase\n",
    "\n",
    "# Definir la cámara fuera de las funciones para acceso global\n",
    "cap = None\n",
    "\n",
    "# Definir las etiquetas de estado de EPP\n",
    "lbl_casco = None\n",
    "lbl_gafas = None\n",
    "lbl_chaleco = None\n",
    "\n",
    "# Crear directorio para almacenar los recortes de detecciones\n",
    "output_dir = \"Resultados_Camara\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Crear directorios para cumplir y no cumplir\n",
    "output_dir_compliance = os.path.join(output_dir, \"Cumple\")\n",
    "output_dir_non_compliance = os.path.join(output_dir, \"NoCumple\")\n",
    "os.makedirs(output_dir_compliance, exist_ok=True)\n",
    "os.makedirs(output_dir_non_compliance, exist_ok=True)\n",
    "\n",
    "# Accedemos a la carpeta con las imágenes de las personas\n",
    "path = 'Personal'\n",
    "images = []\n",
    "nombres = []\n",
    "lista = os.listdir(path)\n",
    "\n",
    "# Leemos los rostros desde la base de datos\n",
    "for archivo in lista:\n",
    "    # Leemos las imágenes de los rostros\n",
    "    imgdb = cv2.imread(f'{path}/{archivo}')\n",
    "    # Almacenamos la imagen\n",
    "    images.append(imgdb)\n",
    "    # Almacenamos el nombre\n",
    "    nombres.append(os.path.splitext(archivo)[0])\n",
    "\n",
    "def codificar_rostros(images):\n",
    "    lista_codificaciones = []\n",
    "    # Iteramos a través de las imágenes para codificarlas\n",
    "    for img in images:\n",
    "        # Corrección de color (de BGR a RGB)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # Codificamos la imagen\n",
    "        codificacion = fr.face_encodings(img)[0]\n",
    "        # Almacenamos la codificación\n",
    "        lista_codificaciones.append(codificacion)\n",
    "    return lista_codificaciones\n",
    "\n",
    "def horario(nombre):\n",
    "    # Abrimos el archivo en modo lectura y escritura\n",
    "    if not os.path.exists('Horario.csv'):\n",
    "        with open('Horario.csv', 'w') as archivo:\n",
    "            archivo.write('Nombre, Fecha, Hora')\n",
    "    with open('Horario.csv', 'r+') as archivo:\n",
    "        # Leemos la información\n",
    "        data = archivo.readlines()\n",
    "        # Creamos una lista para los nombres existentes\n",
    "        lista_nombres = []\n",
    "        # Iteramos cada línea del archivo\n",
    "        for linea in data:\n",
    "            # Buscamos la entrada y la separamos por comas\n",
    "            entrada = linea.split(', ')\n",
    "            # Almacenamos los nombres\n",
    "            lista_nombres.append(entrada[0])\n",
    "        # Verificamos si el nombre no está ya registrado\n",
    "        if nombre not in lista_nombres:\n",
    "            # Extraemos información actual (fecha y hora)\n",
    "            info = datetime.now()\n",
    "            fecha = info.strftime('%Y-%m-%d')\n",
    "            hora = info.strftime('%H:%M:%S')\n",
    "            # Guardamos la información en el archivo\n",
    "            archivo.writelines(f'\\n{nombre}, {fecha}, {hora}')\n",
    "            print(f\"Registro guardado para {nombre} a las {hora} del {fecha}\")\n",
    "\n",
    "# Llamamos a la función para codificar los rostros de la base de datos\n",
    "rostros_codificados = codificar_rostros(images)\n",
    "\n",
    "def cargar_imagenes():\n",
    "    base_path = os.path.abspath(\"Images\")\n",
    "\n",
    "    global img_no_casco, img_no_gafas, img_no_chaleco\n",
    "    global img_si_casco, img_si_gafas, img_si_chaleco\n",
    "\n",
    "    img_no_casco = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"no_casco - copia.png\")))\n",
    "    img_no_gafas = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"no_gafas - copia.png\")))\n",
    "    img_no_chaleco = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"no_chaleco - copia.png\")))\n",
    "    img_si_casco = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"si_casco - copia.png\")))\n",
    "    img_si_gafas = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"si_gafas - copia.png\")))\n",
    "    img_si_chaleco = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"si_chaleco - copia.png\")))\n",
    "\n",
    "def update_epp_status(casco_detected, gafas_detected, chaleco_detected):\n",
    "    # Actualiza las imágenes según las detecciones\n",
    "    if casco_detected:\n",
    "        lbl_casco.config(image=img_si_casco)\n",
    "        lbl_casco.image = img_si_casco\n",
    "    else:\n",
    "        lbl_casco.config(image=img_no_casco)\n",
    "        lbl_casco.image = img_no_casco\n",
    "\n",
    "    if gafas_detected:\n",
    "        lbl_gafas.config(image=img_si_gafas)\n",
    "        lbl_gafas.image = img_si_gafas\n",
    "    else:\n",
    "        lbl_gafas.config(image=img_no_gafas)\n",
    "        lbl_gafas.image = img_no_gafas\n",
    "\n",
    "    if chaleco_detected:\n",
    "        lbl_chaleco.config(image=img_si_chaleco)\n",
    "        lbl_chaleco.image = img_si_chaleco\n",
    "    else:\n",
    "        lbl_chaleco.config(image=img_no_chaleco)\n",
    "        lbl_chaleco.image = img_no_chaleco\n",
    "\n",
    "def draw_boxes(frame, boxes, labels, colors):\n",
    "    casco_detected = gafas_detected = chaleco_detected = False\n",
    "    detected_person = None\n",
    "    detected_items = set()\n",
    "    crop_margin_large = 70  # Margen mayor para el crop específico\n",
    "\n",
    "    for box in boxes:\n",
    "        # Obtenemos la clase del objeto detectado\n",
    "        c = int(box.cls)\n",
    "        \n",
    "        # Solo dibujar la caja si la confianza es mayor o igual a 0.5\n",
    "        if box.conf[0] >= 0.5:\n",
    "            # Extraemos las coordenadas de la caja\n",
    "            r = box.xyxy[0].cpu().numpy()  # Convertimos a numpy\n",
    "            r = [int(coord) for coord in r]  # Convertimos a enteros\n",
    "            x1, y1, x2, y2 = r\n",
    "\n",
    "            # Dibujamos la caja sobre el frame con un borde grueso (4 píxeles)\n",
    "            color = colors[c]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 4)\n",
    "\n",
    "            # Etiqueta con el nombre de la clase\n",
    "            label = f\"{labels[c]}\"\n",
    "\n",
    "            # Definir el tamaño del texto y la ubicación\n",
    "            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "            \n",
    "            # Crear un fondo sólido para la etiqueta\n",
    "            cv2.rectangle(frame, (x1, y1 - h - 10), (x1 + w, y1), color, -1)\n",
    "\n",
    "            # Colocar el texto sobre el fondo\n",
    "            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "            # Realizar un crop de la persona detectada con mayor margen para obtener una imagen más amplia\n",
    "            if labels[c] == \"Persona\":\n",
    "                detected_person = frame[max(0, y1 - crop_margin_large):min(frame.shape[0], y2 + crop_margin_large),\n",
    "                                        max(0, x1 - crop_margin_large):min(frame.shape[1], x2 + crop_margin_large)]\n",
    "            elif labels[c] == \"Gafas\":\n",
    "                gafas_detected = True\n",
    "            elif labels[c] == \"Casco\":\n",
    "                casco_detected = True\n",
    "            elif labels[c] == \"Chaleco\":\n",
    "                chaleco_detected = True\n",
    "                detected_items.add(labels[c])\n",
    "\n",
    "    # Guardar el recorte de la persona si fue detectada\n",
    "    if detected_person is not None and detected_person.size > 0:  # Asegurarse de que el recorte no esté vacío\n",
    "        # Verificar si la persona cumple con todos los EPP\n",
    "        required_items = {\"Gafas\", \"Casco\", \"Chaleco\"}\n",
    "        cumple = required_items.issubset(detected_items)\n",
    "        if cumple:\n",
    "            filename = os.path.join(output_dir_compliance, f\"cumple_persona_{len([f for f in os.listdir(output_dir_compliance) if f.endswith('.png')])}.png\")\n",
    "        else:\n",
    "            filename = os.path.join(output_dir_non_compliance, f\"nocumple_persona_{len([f for f in os.listdir(output_dir_non_compliance) if f.endswith('.png')])}.png\")\n",
    "        # Ajustar el tamaño del crop para ser aproximadamente 550x735 píxeles\n",
    "        detected_person_resized = cv2.resize(detected_person, (550, 735))\n",
    "        cv2.imwrite(filename, detected_person_resized)\n",
    "\n",
    "    # Actualizar la interfaz con el estado de los EPP detectados\n",
    "    update_epp_status(casco_detected, gafas_detected, chaleco_detected)\n",
    "\n",
    "def Scanning():\n",
    "    global cap  # Declarar cap como global para asegurarnos de tener acceso a la cámara\n",
    "\n",
    "    if cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            # Detección de EPP\n",
    "            results = model.predict(frame, stream=True, verbose=False)\n",
    "            for result in results:\n",
    "                draw_boxes(frame, result.boxes, classes, COLORS)\n",
    "            \n",
    "            # Detección facial\n",
    "            frame_pequeño = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "            frame_pequeño = cv2.cvtColor(frame_pequeño, cv2.COLOR_BGR2RGB)\n",
    "            ubicaciones_rostros = fr.face_locations(frame_pequeño, model='hog')\n",
    "            codificaciones_rostros = fr.face_encodings(frame_pequeño, ubicaciones_rostros, num_jitters=1)\n",
    "\n",
    "            for codificacion_rostro, ubicacion_rostro in zip(codificaciones_rostros, ubicaciones_rostros):\n",
    "                coincidencias = fr.compare_faces(rostros_codificados, codificacion_rostro, tolerance=0.6)\n",
    "                nombre = \"Desconocido\"\n",
    "                if True in coincidencias:\n",
    "                    indice_coincidencia = coincidencias.index(True)\n",
    "                    nombre = nombres[indice_coincidencia]\n",
    "                    horario(nombre)\n",
    "                # Escalamos de nuevo las ubicaciones de los rostros al tamaño original del frame\n",
    "                top, right, bottom, left = ubicacion_rostro\n",
    "                top *= 4\n",
    "                right *= 4\n",
    "                bottom *= 4\n",
    "                left *= 4\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 3)\n",
    "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "                cv2.putText(frame, nombre, (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = ImageTk.PhotoImage(image=Image.fromarray(frame_rgb))\n",
    "            lblVideo.configure(image=img)\n",
    "            lblVideo.image = img\n",
    "\n",
    "        lblVideo.after(10, Scanning)\n",
    "\n",
    "def ventana_principal():\n",
    "    global cap, lblVideo, lbl_casco, lbl_gafas, lbl_chaleco\n",
    "\n",
    "    pantalla = Tk()\n",
    "    pantalla.title(\"Detección de EPP y Reconocimiento Facial\")\n",
    "    pantalla.geometry(\"1280x720\")\n",
    "\n",
    "    # Cargar la imagen de fondo\n",
    "    try:\n",
    "        imageF = Image.open(\"canva.jpg\")\n",
    "        imageF = imageF.resize((1280, 720), Image.ANTIALIAS)\n",
    "        imageF = ImageTk.PhotoImage(imageF)\n",
    "        background = Label(pantalla, image=imageF)\n",
    "        background.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "        background.image = imageF\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: No se pudo cargar 'Canva.png'. Asegúrate de que la imagen esté en la misma carpeta.\")\n",
    "\n",
    "    # Cargar las imágenes una vez que la ventana se haya creado\n",
    "    cargar_imagenes()\n",
    "\n",
    "    # Configurar las etiquetas para mostrar las imágenes de estado de EPP en la interfaz\n",
    "    lbl_casco = Label(pantalla, image=img_no_casco, bg='#d9d9d9')  # Fondo gris claro para que destaque\n",
    "    lbl_casco.place(x=75, y=110)\n",
    "    lbl_gafas = Label(pantalla, image=img_no_gafas, bg='#d9d9d9')\n",
    "    lbl_gafas.place(x=75, y=260)\n",
    "    lbl_chaleco = Label(pantalla, image=img_no_chaleco, bg='#d9d9d9')\n",
    "    lbl_chaleco.place(x=75, y=410)\n",
    "\n",
    "    # Configuración del video\n",
    "    lblVideo = Label(pantalla)\n",
    "    lblVideo.place(x=320, y=120)\n",
    "\n",
    "    # Configurar la cámara\n",
    "    cap = cv2.VideoCapture(1)  # 0 indica la cámara por defecto del sistema\n",
    "    if not cap.isOpened():\n",
    "        sys.exit(\"No se pudo acceder a la cámara.\")\n",
    "\n",
    "    # Iniciar la detección\n",
    "    Scanning()\n",
    "    pantalla.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ventana_principal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm246\\AppData\\Local\\Temp\\ipykernel_19652\\745919419.py:241: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  imageF = imageF.resize((1280, 720), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "from ultralytics import YOLO  # Importa la clase YOLO correctamente\n",
    "import numpy as np\n",
    "from tkinter import Tk, Label\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import face_recognition as fr\n",
    "from datetime import datetime\n",
    "\n",
    "# Definir el modelo YOLO como global\n",
    "model = YOLO('best-3.pt')  # Asegúrate de usar la clase/método correcto para YOLO\n",
    "\n",
    "# Definir las clases de tu modelo entrenado\n",
    "classes = ['Gafas', 'Casco', 'Persona', 'Chaleco']  # Clases de tu modelo\n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))  # Colores aleatorios para cada clase\n",
    "\n",
    "# Definir la cámara fuera de las funciones para acceso global\n",
    "cap = None\n",
    "\n",
    "# Definir las etiquetas de estado de EPP\n",
    "lbl_casco = None\n",
    "lbl_gafas = None\n",
    "lbl_chaleco = None\n",
    "\n",
    "# Crear directorio para almacenar los recortes de detecciones\n",
    "output_dir = \"Resultados_Camara\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Crear directorios para cumplir y no cumplir\n",
    "output_dir_compliance = os.path.join(output_dir, \"Cumple\")\n",
    "output_dir_non_compliance = os.path.join(output_dir, \"NoCumple\")\n",
    "os.makedirs(output_dir_compliance, exist_ok=True)\n",
    "os.makedirs(output_dir_non_compliance, exist_ok=True)\n",
    "\n",
    "# Accedemos a la carpeta con las imágenes de las personas\n",
    "path = 'Personal'\n",
    "images = []\n",
    "nombres = []\n",
    "lista = os.listdir(path)\n",
    "\n",
    "# Leemos los rostros desde la base de datos\n",
    "for archivo in lista:\n",
    "    # Leemos las imágenes de los rostros\n",
    "    imgdb = cv2.imread(f'{path}/{archivo}')\n",
    "    # Almacenamos la imagen\n",
    "    images.append(imgdb)\n",
    "    # Almacenamos el nombre\n",
    "    nombres.append(os.path.splitext(archivo)[0])\n",
    "\n",
    "def codificar_rostros(images):\n",
    "    lista_codificaciones = []\n",
    "    # Iteramos a través de las imágenes para codificarlas\n",
    "    for img in images:\n",
    "        # Corrección de color (de BGR a RGB)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # Codificamos la imagen\n",
    "        codificacion = fr.face_encodings(img)[0]\n",
    "        # Almacenamos la codificación\n",
    "        lista_codificaciones.append(codificacion)\n",
    "    return lista_codificaciones\n",
    "\n",
    "def horario(nombre):\n",
    "    # Abrimos el archivo en modo lectura y escritura\n",
    "    if not os.path.exists('Horario.csv'):\n",
    "        with open('Horario.csv', 'w') as archivo:\n",
    "            archivo.write('Nombre, Fecha, Hora')\n",
    "    with open('Horario.csv', 'r+') as archivo:\n",
    "        # Leemos la información\n",
    "        data = archivo.readlines()\n",
    "        # Creamos una lista para los nombres existentes\n",
    "        lista_nombres = []\n",
    "        # Iteramos cada línea del archivo\n",
    "        for linea in data:\n",
    "            # Buscamos la entrada y la separamos por comas\n",
    "            entrada = linea.split(', ')\n",
    "            # Almacenamos los nombres\n",
    "            lista_nombres.append(entrada[0])\n",
    "        # Verificamos si el nombre no está ya registrado\n",
    "        if nombre not in lista_nombres:\n",
    "            # Extraemos información actual (fecha y hora)\n",
    "            info = datetime.now()\n",
    "            fecha = info.strftime('%Y-%m-%d')\n",
    "            hora = info.strftime('%H:%M:%S')\n",
    "            # Guardamos la información en el archivo\n",
    "            archivo.writelines(f'\\n{nombre}, {fecha}, {hora}')\n",
    "            print(f\"Registro guardado para {nombre} a las {hora} del {fecha}\")\n",
    "\n",
    "# Llamamos a la función para codificar los rostros de la base de datos\n",
    "rostros_codificados = codificar_rostros(images)\n",
    "\n",
    "def cargar_imagenes():\n",
    "    base_path = os.path.abspath(\"Images\")\n",
    "\n",
    "    global img_no_casco, img_no_gafas, img_no_chaleco\n",
    "    global img_si_casco, img_si_gafas, img_si_chaleco\n",
    "\n",
    "    img_no_casco = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"no_casco - copia.png\")))\n",
    "    img_no_gafas = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"no_gafas - copia.png\")))\n",
    "    img_no_chaleco = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"no_chaleco - copia.png\")))\n",
    "    img_si_casco = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"si_casco - copia.png\")))\n",
    "    img_si_gafas = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"si_gafas - copia.png\")))\n",
    "    img_si_chaleco = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"si_chaleco - copia.png\")))\n",
    "\n",
    "def update_epp_status(casco_detected, gafas_detected, chaleco_detected):\n",
    "    # Actualiza las imágenes según las detecciones\n",
    "    if casco_detected:\n",
    "        lbl_casco.config(image=img_si_casco)\n",
    "        lbl_casco.image = img_si_casco\n",
    "    else:\n",
    "        lbl_casco.config(image=img_no_casco)\n",
    "        lbl_casco.image = img_no_casco\n",
    "\n",
    "    if gafas_detected:\n",
    "        lbl_gafas.config(image=img_si_gafas)\n",
    "        lbl_gafas.image = img_si_gafas\n",
    "    else:\n",
    "        lbl_gafas.config(image=img_no_gafas)\n",
    "        lbl_gafas.image = img_no_gafas\n",
    "\n",
    "    if chaleco_detected:\n",
    "        lbl_chaleco.config(image=img_si_chaleco)\n",
    "        lbl_chaleco.image = img_si_chaleco\n",
    "    else:\n",
    "        lbl_chaleco.config(image=img_no_chaleco)\n",
    "        lbl_chaleco.image = img_no_chaleco\n",
    "\n",
    "def draw_boxes(frame, boxes, labels, colors):\n",
    "    casco_detected = gafas_detected = chaleco_detected = False\n",
    "    detected_person = None\n",
    "    detected_items = set()\n",
    "    crop_margin_large = 70  # Margen mayor para el crop específico\n",
    "\n",
    "    for box in boxes:\n",
    "        # Obtenemos la clase del objeto detectado\n",
    "        c = int(box.cls)\n",
    "        \n",
    "        # Solo dibujar la caja si la confianza es mayor o igual a 0.5\n",
    "        if box.conf[0] >= 0.5:\n",
    "            # Extraemos las coordenadas de la caja\n",
    "            r = box.xyxy[0].cpu().numpy()  # Convertimos a numpy\n",
    "            r = [int(coord) for coord in r]  # Convertimos a enteros\n",
    "            x1, y1, x2, y2 = r\n",
    "\n",
    "            # Dibujamos la caja sobre el frame con un borde grueso (4 píxeles)\n",
    "            color = colors[c]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 4)\n",
    "\n",
    "            # Etiqueta con el nombre de la clase\n",
    "            label = f\"{labels[c]}\"\n",
    "\n",
    "            # Definir el tamaño del texto y la ubicación\n",
    "            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "            \n",
    "            # Crear un fondo sólido para la etiqueta\n",
    "            cv2.rectangle(frame, (x1, y1 - h - 10), (x1 + w, y1), color, -1)\n",
    "\n",
    "            # Colocar el texto sobre el fondo\n",
    "            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "            # Realizar un crop de la persona detectada con mayor margen para obtener una imagen más amplia\n",
    "            if labels[c] == \"Persona\":\n",
    "                detected_person = frame[max(0, y1 - crop_margin_large):min(frame.shape[0], y2 + crop_margin_large),\n",
    "                                        max(0, x1 - crop_margin_large):min(frame.shape[1], x2 + crop_margin_large)]\n",
    "            elif labels[c] == \"Gafas\":\n",
    "                gafas_detected = True\n",
    "            elif labels[c] == \"Casco\":\n",
    "                casco_detected = True\n",
    "            elif labels[c] == \"Chaleco\":\n",
    "                chaleco_detected = True\n",
    "                detected_items.add(labels[c])\n",
    "\n",
    "    # Guardar el recorte de la persona si fue detectada\n",
    "    if detected_person is not None and detected_person.size > 0:  # Asegurarse de que el recorte no esté vacío\n",
    "        # Verificar si la persona cumple con todos los EPP\n",
    "        required_items = {\"Gafas\", \"Casco\", \"Chaleco\"}\n",
    "        cumple = required_items.issubset(detected_items)\n",
    "        if cumple:\n",
    "            filename = os.path.join(output_dir_compliance, f\"cumple_persona_{len([f for f in os.listdir(output_dir_compliance) if f.endswith('.png')])}.png\")\n",
    "        else:\n",
    "            filename = os.path.join(output_dir_non_compliance, f\"nocumple_persona_{len([f for f in os.listdir(output_dir_non_compliance) if f.endswith('.png')])}.png\")\n",
    "        # Ajustar el tamaño del crop para ser aproximadamente 550x735 píxeles\n",
    "        detected_person_resized = cv2.resize(detected_person, (550, 735))\n",
    "        cv2.imwrite(filename, detected_person_resized)\n",
    "\n",
    "    # Actualizar la interfaz con el estado de los EPP detectados\n",
    "    update_epp_status(casco_detected, gafas_detected, chaleco_detected)\n",
    "\n",
    "def Scanning():\n",
    "    global cap  # Declarar cap como global para asegurarnos de tener acceso a la cámara\n",
    "\n",
    "    if cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            # Detección de EPP\n",
    "            results = model.predict(frame, stream=True, verbose=False)\n",
    "            for result in results:\n",
    "                draw_boxes(frame, result.boxes, classes, COLORS)\n",
    "            \n",
    "            # Detección facial\n",
    "            frame_pequeño = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "            frame_pequeño = cv2.cvtColor(frame_pequeño, cv2.COLOR_BGR2RGB)\n",
    "            ubicaciones_rostros = fr.face_locations(frame_pequeño, model='hog')\n",
    "            codificaciones_rostros = fr.face_encodings(frame_pequeño, ubicaciones_rostros, num_jitters=1)\n",
    "\n",
    "            for codificacion_rostro, ubicacion_rostro in zip(codificaciones_rostros, ubicaciones_rostros):\n",
    "                coincidencias = fr.compare_faces(rostros_codificados, codificacion_rostro, tolerance=0.6)\n",
    "                nombre = \"Desconocido\"\n",
    "                if True in coincidencias:\n",
    "                    indice_coincidencia = coincidencias.index(True)\n",
    "                    nombre = nombres[indice_coincidencia]\n",
    "                    horario(nombre)\n",
    "                # Escalamos de nuevo las ubicaciones de los rostros al tamaño original del frame\n",
    "                top, right, bottom, left = ubicacion_rostro\n",
    "                top *= 4\n",
    "                right *= 4\n",
    "                bottom *= 4\n",
    "                left *= 4\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 3)\n",
    "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "                cv2.putText(frame, nombre, (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = ImageTk.PhotoImage(image=Image.fromarray(frame_rgb))\n",
    "            lblVideo.configure(image=img)\n",
    "            lblVideo.image = img\n",
    "\n",
    "        lblVideo.after(10, Scanning)\n",
    "\n",
    "def ventana_principal():\n",
    "    global cap, lblVideo, lbl_casco, lbl_gafas, lbl_chaleco\n",
    "\n",
    "    pantalla = Tk()\n",
    "    pantalla.title(\"Detección de EPP y Reconocimiento Facial\")\n",
    "    pantalla.geometry(\"1280x720\")\n",
    "\n",
    "    # Cargar la imagen de fondo\n",
    "    try:\n",
    "        imageF = Image.open(\"canva.jpg\")\n",
    "        imageF = imageF.resize((1280, 720), Image.ANTIALIAS)\n",
    "        imageF = ImageTk.PhotoImage(imageF)\n",
    "        background = Label(pantalla, image=imageF)\n",
    "        background.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "        background.image = imageF\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: No se pudo cargar 'Canva.png'. Asegúrate de que la imagen esté en la misma carpeta.\")\n",
    "\n",
    "    # Cargar las imágenes una vez que la ventana se haya creado\n",
    "    cargar_imagenes()\n",
    "\n",
    "    # Configurar las etiquetas para mostrar las imágenes de estado de EPP en la interfaz\n",
    "    lbl_casco = Label(pantalla, image=img_no_casco, bg='#d9d9d9')  # Fondo gris claro para que destaque\n",
    "    lbl_casco.place(x=75, y=110)\n",
    "    lbl_gafas = Label(pantalla, image=img_no_gafas, bg='#d9d9d9')\n",
    "    lbl_gafas.place(x=75, y=260)\n",
    "    lbl_chaleco = Label(pantalla, image=img_no_chaleco, bg='#d9d9d9')\n",
    "    lbl_chaleco.place(x=75, y=410)\n",
    "\n",
    "    # Configuración del video\n",
    "    lblVideo = Label(pantalla)\n",
    "    lblVideo.place(x=320, y=120)\n",
    "\n",
    "    # Configurar la cámara\n",
    "    cap = cv2.VideoCapture(1)  # 0 indica la cámara por defecto del sistema\n",
    "    if not cap.isOpened():\n",
    "        sys.exit(\"No se pudo acceder a la cámara.\")\n",
    "        sys.exit(\"No se pudo acceder a la cámara.\")\n",
    "\n",
    "    # Iniciar la detección\n",
    "    Scanning()\n",
    "    pantalla.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ventana_principal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "----- BEST 4 ----- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm246\\AppData\\Local\\Temp\\ipykernel_21100\\4184197820.py:180: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  imageF = imageF.resize((1280, 720), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "from ultralytics import YOLO  # Importa la clase YOLO correctamente\n",
    "import numpy as np\n",
    "from tkinter import Tk, Label\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import face_recognition as fr\n",
    "from datetime import datetime\n",
    "\n",
    "# Cargar el modelo YOLO recién entrenado\n",
    "model = YOLO('best4.pt')  # Cambiar a tu nuevo modelo\n",
    "\n",
    "# Unificación de clases similares\n",
    "class_mapping = {\n",
    "    'Helmet': 'Casco', 'helmet': 'Casco', 'No-Helmet': 'NoCasco', 'no helmet': 'NoCasco', 'no_helmet': 'NoCasco',\n",
    "    'Safety-Vest': 'Chaleco', 'Reflective-Vest': 'Chaleco', 'Vest': 'Chaleco', 'Yelek': 'Chaleco', 'safety vest - v1 2023-11-19 5-12pm': 'Chaleco', 'no vest': 'NoChaleco', 'no_vest': 'NoChaleco', 'vest': 'Chaleco',\n",
    "    'Goggles': 'Gafas', 'Glasses': 'Gafas', 'Glass': 'Gafas',\n",
    "    'Person': 'Persona', 'worker': 'Persona',\n",
    "    'Safety-Boot': 'Bota', 'safetyboot': 'Bota', 'protective_suit': 'Traje',\n",
    "    'Gloves': 'Guantes'  # Mapeo para guantes\n",
    "}\n",
    "\n",
    "# Lista de clases finales a considerar\n",
    "final_classes = list(set(class_mapping.values()))  # Extraer clases únicas\n",
    "COLORS = np.random.uniform(0, 255, size=(len(final_classes), 3))  # Colores aleatorios para cada clase\n",
    "\n",
    "# Definir la cámara fuera de las funciones para acceso global\n",
    "cap = None\n",
    "\n",
    "# Definir las etiquetas de estado de EPP\n",
    "lbl_casco = None\n",
    "lbl_gafas = None\n",
    "lbl_chaleco = None\n",
    "\n",
    "# Crear directorio para almacenar los recortes de detecciones\n",
    "output_dir = \"Resultados_Camara\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Crear directorios para cumplir y no cumplir\n",
    "output_dir_compliance = os.path.join(output_dir, \"Cumple\")\n",
    "output_dir_non_compliance = os.path.join(output_dir, \"NoCumple\")\n",
    "os.makedirs(output_dir_compliance, exist_ok=True)\n",
    "os.makedirs(output_dir_non_compliance, exist_ok=True)\n",
    "\n",
    "# Accedemos a la carpeta con las imágenes de las personas\n",
    "path = 'Personal'\n",
    "images = []\n",
    "nombres = []\n",
    "lista = os.listdir(path)\n",
    "\n",
    "# Leer y almacenar rostros desde la base de datos\n",
    "for archivo in lista:\n",
    "    imgdb = cv2.imread(f'{path}/{archivo}')\n",
    "    images.append(imgdb)\n",
    "    nombres.append(os.path.splitext(archivo)[0])\n",
    "\n",
    "def codificar_rostros(images):\n",
    "    lista_codificaciones = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        codificacion = fr.face_encodings(img)[0]\n",
    "        lista_codificaciones.append(codificacion)\n",
    "    return lista_codificaciones\n",
    "\n",
    "def horario(nombre):\n",
    "    if not os.path.exists('Horario.csv'):\n",
    "        with open('Horario.csv', 'w') as archivo:\n",
    "            archivo.write('Nombre, Fecha, Hora')\n",
    "    with open('Horario.csv', 'r+') as archivo:\n",
    "        data = archivo.readlines()\n",
    "        lista_nombres = [linea.split(', ')[0] for linea in data]\n",
    "        if nombre not in lista_nombres:\n",
    "            info = datetime.now()\n",
    "            fecha = info.strftime('%Y-%m-%d')\n",
    "            hora = info.strftime('%H:%M:%S')\n",
    "            archivo.writelines(f'\\n{nombre}, {fecha}, {hora}')\n",
    "            print(f\"Registro guardado para {nombre} a las {hora} del {fecha}\")\n",
    "\n",
    "# Codificar rostros de la base de datos\n",
    "rostros_codificados = codificar_rostros(images)\n",
    "\n",
    "def cargar_imagenes():\n",
    "    base_path = os.path.abspath(\"Images\")\n",
    "    global img_no_casco, img_no_gafas, img_no_chaleco\n",
    "    global img_si_casco, img_si_gafas, img_si_chaleco\n",
    "\n",
    "    img_no_casco = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"no_casco - copia.png\")))\n",
    "    img_no_gafas = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"no_gafas - copia.png\")))\n",
    "    img_no_chaleco = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"no_chaleco - copia.png\")))\n",
    "    img_si_casco = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"si_casco - copia.png\")))\n",
    "    img_si_gafas = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"si_gafas - copia.png\")))\n",
    "    img_si_chaleco = ImageTk.PhotoImage(Image.open(os.path.join(base_path, \"si_chaleco - copia.png\")))\n",
    "\n",
    "def update_epp_status(casco_detected, gafas_detected, chaleco_detected):\n",
    "    if casco_detected:\n",
    "        lbl_casco.config(image=img_si_casco)\n",
    "        lbl_casco.image = img_si_casco\n",
    "    else:\n",
    "        lbl_casco.config(image=img_no_casco)\n",
    "        lbl_casco.image = img_no_casco\n",
    "\n",
    "    if gafas_detected:\n",
    "        lbl_gafas.config(image=img_si_gafas)\n",
    "        lbl_gafas.image = img_si_gafas\n",
    "    else:\n",
    "        lbl_gafas.config(image=img_no_gafas)\n",
    "        lbl_gafas.image = img_no_gafas\n",
    "\n",
    "    if chaleco_detected:\n",
    "        lbl_chaleco.config(image=img_si_chaleco)\n",
    "        lbl_chaleco.image = img_si_chaleco\n",
    "    else:\n",
    "        lbl_chaleco.config(image=img_no_chaleco)\n",
    "        lbl_chaleco.image = img_no_chaleco\n",
    "\n",
    "def draw_boxes(frame, boxes, colors):\n",
    "    casco_detected = gafas_detected = chaleco_detected = False\n",
    "    detected_person = None\n",
    "    detected_items = set()\n",
    "    crop_margin_large = 70\n",
    "\n",
    "    for box in boxes:\n",
    "        c = int(box.cls)\n",
    "        label_raw = model.names[c]  # Obtener la clase original\n",
    "        label = class_mapping.get(label_raw, label_raw)  # Mapear a clase unificada\n",
    "\n",
    "        if box.conf[0] >= 0.5:\n",
    "            r = box.xyxy[0].cpu().numpy()\n",
    "            r = [int(coord) for coord in r]\n",
    "            x1, y1, x2, y2 = r\n",
    "            color = colors[final_classes.index(label)]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 4)\n",
    "            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "            cv2.rectangle(frame, (x1, y1 - h - 10), (x1 + w, y1), color, -1)\n",
    "            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "            if label == \"Persona\":\n",
    "                detected_person = frame[max(0, y1 - crop_margin_large):min(frame.shape[0], y2 + crop_margin_large),\n",
    "                                        max(0, x1 - crop_margin_large):min(frame.shape[1], x2 + crop_margin_large)]\n",
    "            elif label == \"Gafas\":\n",
    "                gafas_detected = True\n",
    "            elif label == \"Casco\":\n",
    "                casco_detected = True\n",
    "            elif label == \"Chaleco\":\n",
    "                chaleco_detected = True\n",
    "                detected_items.add(label)\n",
    "\n",
    "    update_epp_status(casco_detected, gafas_detected, chaleco_detected)\n",
    "\n",
    "def Scanning():\n",
    "    global cap\n",
    "    if cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            results = model.predict(frame, stream=True, verbose=False)\n",
    "            for result in results:\n",
    "                draw_boxes(frame, result.boxes, COLORS)\n",
    "            \n",
    "            # Procesamiento de reconocimiento facial\n",
    "            # [Agrega el código de reconocimiento facial aquí si es necesario]\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = ImageTk.PhotoImage(image=Image.fromarray(frame_rgb))\n",
    "            lblVideo.configure(image=img)\n",
    "            lblVideo.image = img\n",
    "\n",
    "        lblVideo.after(10, Scanning)\n",
    "\n",
    "def ventana_principal():\n",
    "    global cap, lblVideo, lbl_casco, lbl_gafas, lbl_chaleco\n",
    "\n",
    "    pantalla = Tk()\n",
    "    pantalla.title(\"Detección de EPP y Reconocimiento Facial\")\n",
    "    pantalla.geometry(\"1280x720\")\n",
    "\n",
    "    try:\n",
    "        imageF = Image.open(\"canva.jpg\")\n",
    "        imageF = imageF.resize((1280, 720), Image.ANTIALIAS)\n",
    "        imageF = ImageTk.PhotoImage(imageF)\n",
    "        background = Label(pantalla, image=imageF)\n",
    "        background.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "        background.image = imageF\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: No se pudo cargar 'Canva.png'. Asegúrate de que la imagen esté en la misma carpeta.\")\n",
    "\n",
    "    cargar_imagenes()\n",
    "\n",
    "    lbl_casco = Label(pantalla, image=img_no_casco, bg='#d9d9d9')\n",
    "    lbl_casco.place(x=75, y=110)\n",
    "    lbl_gafas = Label(pantalla, image=img_no_gafas, bg='#d9d9d9')\n",
    "    lbl_gafas.place(x=75, y=260)\n",
    "    lbl_chaleco = Label(pantalla, image=img_no_chaleco, bg='#d9d9d9')\n",
    "    lbl_chaleco.place(x=75, y=410)\n",
    "\n",
    "    lblVideo = Label(pantalla)\n",
    "    lblVideo.place(x=320, y=120)\n",
    "\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        sys.exit(\"No se pudo acceder a la cámara.\")\n",
    "\n",
    "    Scanning()\n",
    "    pantalla.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ventana_principal()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
